# Import Restaurants from CSV

## Quick Start

1. **Make sure slug system columns exist:**
   - Run `database/add-slug-system.sql` in Supabase SQL Editor first
   - This adds `country_code` and `restaurant_number` columns

2. **Run the import script:**
   ```bash
   npm run import:csv
   ```

## What It Does

- âœ… Reads CSV file from: `C:\Users\matth\OneDrive\Bureaublad\Werk\BiteReserve\New folder (2)\restaurants_rows.csv`
- âœ… Parses all rows
- âœ… Filters rows with valid `country_iso_code` and `bitereserve_code`
- âœ… Generates slugs: `r/[country_code]/[5-digit-number]`
- âœ… Converts data types (cuisines â†’ array, hours â†’ JSONB, rating â†’ decimal)
- âœ… Inserts in batches of 50 (to avoid timeouts)
- âœ… Uses upsert (updates if exists, inserts if new)
- âœ… Shows progress and final statistics

## Expected Output

```
ðŸ“– Reading CSV file...
ðŸ“Š Parsing CSV...
âœ… Found 3200 restaurants
âœ… 3200 restaurants have valid country_iso_code and bitereserve_code

ðŸ“¥ Inserting into restaurants table in batches...
âœ… Imported 3200/3200 restaurants...

âœ… Successfully imported 3200 restaurants

ðŸ“Š Verifying import...
âœ… Total restaurants in database: 3200
âœ… Countries: aw, br, jm, nl, us, ...

ðŸŽ‰ Import complete!
```

## Troubleshooting

**Error: "column country_code does not exist"**
- Run `database/add-slug-system.sql` first!

**Error: "relation restaurants does not exist"**
- Run `database/schema.sql` first to create all tables

**Import is slow**
- This is normal for 3200+ restaurants
- The script shows progress as it imports

**Some rows fail**
- Check the error messages
- Common issues: invalid JSON in `opening_hours` or `cuisines`
- The script continues even if some batches fail
